{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 01 - Pitfalls in Data Mining     \n",
    "## CSCI E-96\n",
    "\n",
    "The goal of data mining is to find important relationships in large complex datasets. These dataset typically contain a large number of variables. The **high-dimensional** nature of the data leads to some commonly encountered pitfalls which lead to incorrect inferences.   \n",
    "\n",
    "In this assignment you will gain a bit of experience with three important concepts in data mining:  \n",
    "\n",
    "1. **False Discovery Rate Control:** The goal of data mining is to find important relationships in large complex datasets. These dataset typically contain a large number of variables. The **high-dimensional** nature of the data leads to some commonly encountered pitfalls which lead to incorrect inferences. A related problem is cutting off a large-scale analysis when a desired relationship is 'found'. This practice of **p-value mining** often leads to unwarranted inferences. You will apply false discovery rate (FDR) control methods to address this problem.   \n",
    "2. **Key-Value Pairs:** Large scale data is typically managed using key-value (KV) pairs. The exercises in this assignment give you some experience working with KV pair data management.  \n",
    "3. **Map and Reduce Processes:** Much of large scale data mining requires use of a split-apply-combine approach. The data is split into manageable chunks, analytic transformations are applied, and the result combined or aggregated. A commonly used class of a split-apply-combine algorithm is MapReduce. \n",
    "\n",
    "In order to keep the scope of this assignment manageable, you will use limited versions of KV pair management and MapReduce. Specifically, you will use common Python tools to implement these concepts rather than dedicated large scale analytic platforms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Hypothesis Tesing\n",
    "\n",
    "Testing multiple hypothesis in high-dimensional data can be problematic. Exhaustively testing all pairwise relationships between variables in a data set is a commonly used, but generally misleading from of **multiple comparisons**. The chance of finding false significance, using such a **data dredging** approach, can be surprisingly high. \n",
    "\n",
    "In this exercise you will perform multiple comparisons on only 20 **identically distributed independent (iid)** variables. Ideally, such tests should not find significant relationships, but the actual result is quite different. \n",
    "\n",
    "To get started, execute the code in the cell below to load the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "from itertools import product, combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.stats.multitest as smt\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will apply a t-test to all pairwise combinations of identical Normally distributed variables. In this case, we will create a data set with 20 iid Normal distributions of 1000 samples each. Execute the code in the cell below to find this data and display the mean and variance of each variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The means of the columns are\n",
      " [-1.16191649e-01  2.80829317e-02 -1.78516419e-02 -1.44691489e-02\n",
      "  3.03718152e-02  1.20007442e-02 -9.58845606e-05  1.98662580e-03\n",
      "  4.94154934e-02 -4.11640866e-02 -6.32977862e-03 -5.93868192e-02\n",
      " -2.56373595e-02  1.43568791e-02 -1.44725765e-02 -1.37023955e-02\n",
      "  1.80622439e-02  5.87029691e-02 -2.02650514e-02 -1.56346106e-02]\n",
      "\n",
      "The variances of the columns are\n",
      " [0.94834508 1.04744241 1.0258018  0.96977571 1.0089001  1.04113864\n",
      " 1.00657222 0.99192594 1.04713487 1.04329434 1.04023108 0.96791346\n",
      " 1.03706907 1.07179865 1.01431404 1.05060289 1.02054329 0.9686211\n",
      " 1.02810287 0.99521555]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ncolumns = 20\n",
    "nr.seed(234)\n",
    "normal_vars = nr.normal(size=(1000,ncolumns))\n",
    "print('The means of the columns are\\n', np.mean(normal_vars, axis = 0))\n",
    "print('\\nThe variances of the columns are\\n', np.var(normal_vars, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that means and variances are close to 0.0 and 1.0 respectively. As expected, there is not much difference between these variables.\n",
    "\n",
    "How many of these t-tests will show **significance** at the 0.05 cut-off level? There are 380 pairwise combinations, so we expect to find a number of falsely significant test results at this level. To find out, complete and execute the code in the cell below to filter the test results and print those that show significance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a hash \n",
    "\n",
    "The goal of this exercise is to compute pairwise hypothesis tests of the differences in means for each of the iid Normal vectors. As an intermediate step you will create a Pandas data frame using a hash of the keys of the vectors. The data frame will contain the **key-value**, $(K,V)$, pairs. Each key must represent an index for the two vectors used to compute the test statistic. The keys will then be used to index the results of these hypothesis tests. \n",
    "\n",
    "The question is, how can we create a hash from the keys for the pair of vectors? In this case to we will use a simple, but far from optimal hash. For the two vector indicies $i, j$, for some key and modulo, $m$, we will compute the hash as:  \n",
    "\n",
    "$$h(i,j) = (i + key*j) mod m$$\n",
    "\n",
    "> **Computational Note:** The Pandas data frame is an efficient and reasonably scalable **hash table**. The hash function used depends on the type of the key; integer, string, etc. The resulting dictionary of key-value pairs, $(K,V)$, can therefore be access in far less than linear time, often about $O(log(N))$.  \n",
    "\n",
    "If you are not familiar with Python dictionaries you can find a short tutorial [here](https://www.tutorialspoint.com/python_data_structure/python_hash_table.htm), as well as many other places on the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1-1:** Given that our space of vectors is actually quite small, just 20, we do not need a sophisticated and scalable hash function. This hashed key will then be used to store and retrieve the values using a Python dictionary, in about $O(log(N))$ time.     \n",
    "\n",
    "> In this exercise you will test a simple hash function and its inverse. Examine the code below and notice that the hash function encodes the two indexes into a single integer by simple additional and multiplication. The modulo operation limits the size of the hash table. However, to keep things simple you will not need to implement any hash collision resolution mechanism. As a result, the size of the table is set much larger than required.  \n",
    "\n",
    "> To test this hash, do the following:    \n",
    "> 1. Create a function called hash function to compute the hash. The arguments to the function are $i$ and $j$, the `hash\\_key` and the `modulo\\_multiplier`. The defaults of the arguments are $hash\\_key=1024$ and $modulo\\_multiplier=32$. The modulo number is $hash\\_key * modulo\\_multiplier$, e.g. $modulo = 32,768$. The multiplier is the ratio of expected values stored, $n$, to the number of unique hash keys, $m$, e.g. the ratio $m/n$.\n",
    "> 2. Using the Python [ittertools.combinations](https://docs.python.org/3/library/itertools.html#itertools.combinations) function create all unique pairwise combinations of indexes i and j. The arguments to this function are the indexes to the iid Normal vectors. The iterator is `range(ncolumns)` choose 2, since these comparisons are pairwise.    \n",
    "> 3. Within this loop call the hash with the values of $i$ and $j$ as arguments.   \n",
    "> 3. On a single line print the following; the values of i and j, the hash key value, but only if $i \\le 6$. The restriction is to keep the printed output shorter.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT: 1:  hash[(0 , 1)] : 1024\n",
      "COUNT: 2:  hash[(0 , 2)] : 2048\n",
      "COUNT: 3:  hash[(0 , 3)] : 3072\n",
      "COUNT: 4:  hash[(0 , 4)] : 4096\n",
      "COUNT: 5:  hash[(0 , 5)] : 5120\n",
      "COUNT: 6:  hash[(0 , 6)] : 6144\n",
      "COUNT: 7:  hash[(0 , 7)] : 7168\n",
      "COUNT: 8:  hash[(0 , 8)] : 8192\n",
      "COUNT: 9:  hash[(0 , 9)] : 9216\n",
      "COUNT: 10:  hash[(0 , 10)] : 10240\n",
      "COUNT: 11:  hash[(0 , 11)] : 11264\n",
      "COUNT: 12:  hash[(0 , 12)] : 12288\n",
      "COUNT: 13:  hash[(0 , 13)] : 13312\n",
      "COUNT: 14:  hash[(0 , 14)] : 14336\n",
      "COUNT: 15:  hash[(0 , 15)] : 15360\n",
      "COUNT: 16:  hash[(0 , 16)] : 16384\n",
      "COUNT: 17:  hash[(0 , 17)] : 17408\n",
      "COUNT: 18:  hash[(0 , 18)] : 18432\n",
      "COUNT: 19:  hash[(0 , 19)] : 19456\n",
      "COUNT: 20:  hash[(1 , 2)] : 2050\n",
      "COUNT: 21:  hash[(1 , 3)] : 3075\n",
      "COUNT: 22:  hash[(1 , 4)] : 4100\n",
      "COUNT: 23:  hash[(1 , 5)] : 5125\n",
      "COUNT: 24:  hash[(1 , 6)] : 6150\n",
      "COUNT: 25:  hash[(1 , 7)] : 7175\n",
      "COUNT: 26:  hash[(1 , 8)] : 8200\n",
      "COUNT: 27:  hash[(1 , 9)] : 9225\n",
      "COUNT: 28:  hash[(1 , 10)] : 10250\n",
      "COUNT: 29:  hash[(1 , 11)] : 11275\n",
      "COUNT: 30:  hash[(1 , 12)] : 12300\n",
      "COUNT: 31:  hash[(1 , 13)] : 13325\n",
      "COUNT: 32:  hash[(1 , 14)] : 14350\n",
      "COUNT: 33:  hash[(1 , 15)] : 15375\n",
      "COUNT: 34:  hash[(1 , 16)] : 16400\n",
      "COUNT: 35:  hash[(1 , 17)] : 17425\n",
      "COUNT: 36:  hash[(1 , 18)] : 18450\n",
      "COUNT: 37:  hash[(1 , 19)] : 19475\n",
      "COUNT: 38:  hash[(2 , 3)] : 3078\n",
      "COUNT: 39:  hash[(2 , 4)] : 4104\n",
      "COUNT: 40:  hash[(2 , 5)] : 5130\n",
      "COUNT: 41:  hash[(2 , 6)] : 6156\n",
      "COUNT: 42:  hash[(2 , 7)] : 7182\n",
      "COUNT: 43:  hash[(2 , 8)] : 8208\n",
      "COUNT: 44:  hash[(2 , 9)] : 9234\n",
      "COUNT: 45:  hash[(2 , 10)] : 10260\n",
      "COUNT: 46:  hash[(2 , 11)] : 11286\n",
      "COUNT: 47:  hash[(2 , 12)] : 12312\n",
      "COUNT: 48:  hash[(2 , 13)] : 13338\n",
      "COUNT: 49:  hash[(2 , 14)] : 14364\n",
      "COUNT: 50:  hash[(2 , 15)] : 15390\n",
      "COUNT: 51:  hash[(2 , 16)] : 16416\n",
      "COUNT: 52:  hash[(2 , 17)] : 17442\n",
      "COUNT: 53:  hash[(2 , 18)] : 18468\n",
      "COUNT: 54:  hash[(2 , 19)] : 19494\n",
      "COUNT: 55:  hash[(3 , 4)] : 4108\n",
      "COUNT: 56:  hash[(3 , 5)] : 5135\n",
      "COUNT: 57:  hash[(3 , 6)] : 6162\n",
      "COUNT: 58:  hash[(3 , 7)] : 7189\n",
      "COUNT: 59:  hash[(3 , 8)] : 8216\n",
      "COUNT: 60:  hash[(3 , 9)] : 9243\n",
      "COUNT: 61:  hash[(3 , 10)] : 10270\n",
      "COUNT: 62:  hash[(3 , 11)] : 11297\n",
      "COUNT: 63:  hash[(3 , 12)] : 12324\n",
      "COUNT: 64:  hash[(3 , 13)] : 13351\n",
      "COUNT: 65:  hash[(3 , 14)] : 14378\n",
      "COUNT: 66:  hash[(3 , 15)] : 15405\n",
      "COUNT: 67:  hash[(3 , 16)] : 16432\n",
      "COUNT: 68:  hash[(3 , 17)] : 17459\n",
      "COUNT: 69:  hash[(3 , 18)] : 18486\n",
      "COUNT: 70:  hash[(3 , 19)] : 19513\n",
      "COUNT: 71:  hash[(4 , 5)] : 5140\n",
      "COUNT: 72:  hash[(4 , 6)] : 6168\n",
      "COUNT: 73:  hash[(4 , 7)] : 7196\n",
      "COUNT: 74:  hash[(4 , 8)] : 8224\n",
      "COUNT: 75:  hash[(4 , 9)] : 9252\n",
      "COUNT: 76:  hash[(4 , 10)] : 10280\n",
      "COUNT: 77:  hash[(4 , 11)] : 11308\n",
      "COUNT: 78:  hash[(4 , 12)] : 12336\n",
      "COUNT: 79:  hash[(4 , 13)] : 13364\n",
      "COUNT: 80:  hash[(4 , 14)] : 14392\n",
      "COUNT: 81:  hash[(4 , 15)] : 15420\n",
      "COUNT: 82:  hash[(4 , 16)] : 16448\n",
      "COUNT: 83:  hash[(4 , 17)] : 17476\n",
      "COUNT: 84:  hash[(4 , 18)] : 18504\n",
      "COUNT: 85:  hash[(4 , 19)] : 19532\n",
      "COUNT: 86:  hash[(5 , 6)] : 6174\n",
      "COUNT: 87:  hash[(5 , 7)] : 7203\n",
      "COUNT: 88:  hash[(5 , 8)] : 8232\n",
      "COUNT: 89:  hash[(5 , 9)] : 9261\n",
      "COUNT: 90:  hash[(5 , 10)] : 10290\n",
      "COUNT: 91:  hash[(5 , 11)] : 11319\n",
      "COUNT: 92:  hash[(5 , 12)] : 12348\n",
      "COUNT: 93:  hash[(5 , 13)] : 13377\n",
      "COUNT: 94:  hash[(5 , 14)] : 14406\n",
      "COUNT: 95:  hash[(5 , 15)] : 15435\n",
      "COUNT: 96:  hash[(5 , 16)] : 16464\n",
      "COUNT: 97:  hash[(5 , 17)] : 17493\n",
      "COUNT: 98:  hash[(5 , 18)] : 18522\n",
      "COUNT: 99:  hash[(5 , 19)] : 19551\n",
      "COUNT: 100:  hash[(6 , 7)] : 7210\n",
      "COUNT: 101:  hash[(6 , 8)] : 8240\n",
      "COUNT: 102:  hash[(6 , 9)] : 9270\n",
      "COUNT: 103:  hash[(6 , 10)] : 10300\n",
      "COUNT: 104:  hash[(6 , 11)] : 11330\n",
      "COUNT: 105:  hash[(6 , 12)] : 12360\n",
      "COUNT: 106:  hash[(6 , 13)] : 13390\n",
      "COUNT: 107:  hash[(6 , 14)] : 14420\n",
      "COUNT: 108:  hash[(6 , 15)] : 15450\n",
      "COUNT: 109:  hash[(6 , 16)] : 16480\n",
      "COUNT: 110:  hash[(6 , 17)] : 17510\n",
      "COUNT: 111:  hash[(6 , 18)] : 18540\n",
      "COUNT: 112:  hash[(6 , 19)] : 19570\n"
     ]
    }
   ],
   "source": [
    "def hash_function(i, j, hash_key=1024, modulo_multiplier=32):\n",
    "    ## Put your code below. \n",
    "    ## Simple function is returned\n",
    "    ##returns ((i + hash_key) * j) % modulo_multiplier\n",
    "    return  ((i + hash_key) * j) % (hash_key*modulo_multiplier)\n",
    "\n",
    "count =0\n",
    "hash = {}\n",
    "harr =  []\n",
    "\n",
    "for i,j in combinations(range(ncolumns), 2):\n",
    "    #if i <= 6: \n",
    "        \n",
    "    #    print( ' Count = ' + str(count))\n",
    "    hash[(i,j)] =     hash_function(i,j)\n",
    "    harr.append( hash_function(i,j))\n",
    "\n",
    "        ##print('i = ' + str(i) + '  j = ' + str(j) + '   hash = ' + str(hash) + '     Count hash = ' + str(count+1))\n",
    "    count += 1\n",
    "    combCount = 1\n",
    "        \n",
    "for i,j in combinations(range(ncolumns),2):     \n",
    "    if i<= 6:\n",
    "        print('COUNT: '+ str(combCount) + ':  hash[(' + str(i)+ ' , '+ str( j) + ')] : ' + str(hash[i,j]))\n",
    "    combCount += 1\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Examine the key pairs and the hash values. The question is, are there any hash collisions? This can be done as follows:   \n",
    "ANSWER: No there are not. I checked the Reoccurrances of each hash value and they were 1\n",
    "> 5. Compute a list of the hash values for all combinations of $i$ and $j$. \n",
    "ANSWER: Shown in the above cell\n",
    "     with hash[(i,j)] : hash value listed for each count\n",
    "> 6. Print the length of the list.  \n",
    "> 7. Print the length of the unique values of the hash. You can find the unique values in a list with the [numpy.unique](https://numpy.org/doc/stable/reference/generated/numpy.unique.html) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Length of the list is: 190\n",
      " The Total Number of unique instances is: 190\n"
     ]
    }
   ],
   "source": [
    "## Put your code below. \n",
    "\n",
    "Count1 = 0\n",
    "# using the function np.unique we create a array with only unique values on the Hash function value\n",
    "ui, harr_u = np.unique(harr,return_counts = True)\n",
    "\n",
    "#for uindex in range(len(harr_u)):\n",
    "#    Count1 += 1\n",
    "#    print('harr_unique(' + str(uindex) + '): ' + str(ui[uindex]) + ' Reoccurrances: '+ str(harr_u[uindex]))\n",
    "print(' The Length of the list is: '+ str(len(harr)))\n",
    "print(' The Total Number of unique instances is: '+ str(len(harr_u)))\n",
    "\n",
    "##print(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Examine the results you have printed. Is there any evidence of hash key collisions?     \n",
    "> The ratio of $m/n$ is deliberately kept high since the simple hash function has no collision resolution mechanism. Optionally, you can try reducing this ration (the multiplier) to 16 and 8, noting the increase in hash collisions.  \n",
    "> **End of exercise.**\n",
    "\n",
    "ANSWER: The length of the list is 190/ The Total number of unique instatnces is 190.\n",
    "So there are no evidence of hash collisions in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No: There is no evidence of hash key collisions. There are 190 Combinations with 190 unique values. Each reoccurance has been determined for the unique hash values indicating the number of collisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The map process\n",
    "\n",
    "We are constructing this example a map and a reduce process. The processes are intended to compute the hypothesis test for differences of means between all the pairs of vectors. The first step is the map process, which creates the keys, or values of $i$ and $j$ for these pairs.   \n",
    "\n",
    "> **Exercise 1-2:** You will now create the code for the map task which build a data frame with $i, j$ key pairs indexed by the hash. By the following steps you will create code that represents a map task.  \n",
    "> 1. Create a data frame with two columns $i$ and $j$ with rows $= hash_key * modulo_multiplier $ and set all values to $= numpy.nan$.\n",
    "> 2. Create a loop over all combinations of the pairs of i and j.   Done\n",
    "> 3. Compute the hash key value for the indexes, i and j. \n",
    "> 4. Add the $i$ and $j$ values to the row indexed by the hash key.  \n",
    "> 5. Return the hash table. ANSWER: used the hash function as the index\n",
    "> 6. Execute the function to create the hash table.  \n",
    "> 7. Compute and print the length of the hash table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_ARR\n",
      "      i  j  hash\n",
      "1024  0  1  1024\n",
      "2048  0  2  2048\n",
      "3072  0  3  3072\n",
      "4096  0  4  4096\n",
      "5120  0  5  5120\n",
      "Length of Hash Table is: 190\n"
     ]
    }
   ],
   "source": [
    "def map_hypothesis(vars, hash_key=1024, modulo_multiplier=32):\n",
    "\n",
    "# clean up\n",
    "\n",
    "    arr = [[], []]\n",
    "    arr_vals = []\n",
    "    hash_arr = []\n",
    "    arr = [[0,0],\n",
    "           [0,1],\n",
    "           [1,0],\n",
    "           [1,1],\n",
    "           [1,2]]\n",
    "    lenrow = len(arr)\n",
    "    lencol = len(arr[0])\n",
    "    ind = 0\n",
    "\n",
    "    ## make the index or rows\n",
    "    ##creates a data frame 'blank'\n",
    "    df = pd.DataFrame(arr)\n",
    "    \n",
    "    ##1. Creates two columns i, j\n",
    "    df.columns = ['i','j']\n",
    "\n",
    "    # declarations\n",
    "    ncols = vars.shape[1]\n",
    "    ncols1 = len(vars[0])\n",
    "    j_val = []\n",
    "    hash_val = []\n",
    "    ncolumns = ncols\n",
    "    #print('ncols-shape :' + str(ncols) + ' ncols1-len(vars[0]) :' + str(ncols1))\n",
    "\n",
    "    ## J goes from 0 to 19\n",
    "    ind = 0\n",
    "    #2. loops over all combinations of i, j for ncols length=20 in pairs of 2\n",
    "    for i,j in combinations(range(ncols), 2):\n",
    "        \n",
    "        ind += 1\n",
    "    #3. using the function hash_function(i,j) it computes the hash for given function    \n",
    "        hash[(i,j)] = hash_function(i,j)\n",
    "        hash_arr.append(hash_function(i,j))\n",
    "        hash_val.append( hash[(i,j)])\n",
    "    #4. This newRow will add the cols i,j when the arr_vals are assigned all at once\n",
    "        newRow = (i,j,hash[i,j])\n",
    "        arr_vals.append(newRow)\n",
    "\n",
    "    df_arr = pd.DataFrame(arr_vals)\n",
    "   \n",
    "    df_arr.columns = ['i','j', 'hash']\n",
    "    df_arr.loc[:,'hash'] = pd.DataFrame(hash_val)\n",
    "    combCount = 1\n",
    "    df_arr.index = hash_arr\n",
    "    print('DF_ARR')\n",
    "    print(df_arr.head())\n",
    "    #5. returns the hash table\n",
    "    return df_arr \n",
    " \n",
    "\n",
    "#6. Execute the function to create the hash table.\n",
    "hash_table = map_hypothesis(normal_vars)\n",
    "#7. Compute and print the length of the hash table.\n",
    "print('Length of Hash Table is: '+ str(len(hash_table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The shuffle and reduce task\n",
    "\n",
    "Now that you have the keys for the pairwise combinations of the vectors it is time to perform the reduce process. The reduce process computes the pair-wise t-statistics and p-values. These statistical values are indexed by the keys of the pair of vectors. This process reduces the full vectors of values down to just two numbers for each pair of vectors. \n",
    "\n",
    "> **Exercise 1-3:** You will now create and apply the following code for the reduce process:   \n",
    "> 1. Create an empty data frame with columns, `i`, `j`, `t_statistic`, and `p_value`.    \n",
    "> 2. Using a for loop iterate over all possible (hashed) keys of the data frame. An if statement is used to test if these are valid values of the key, i. Use the [numpy.isnan](https://numpy.org/doc/stable/reference/generated/numpy.isnan.html) function for this test.  \n",
    "> 3. Extract the values of i and j from the input data frame. \n",
    "> 4. Using keys, compute the t-statistic and p-value using [scipy.stats import ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html).\n",
    "> 5. Append a row to the output data frame.\n",
    "> 6. Return the data frame, sorted in ascending order, using the [Pandas.DataFrame.sort_values](https://turned.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) method and re-indexed using the [Pandas.DataFrame.reset_index](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) method.    \n",
    "> 7. Execute your function and save the returned data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(hash_table): 190\n",
      "len(tt_arr): 190\n",
      "len(pv_arr): 190\n",
      "len(sig_arr): 190\n",
      "Sig-Count: 22\n"
     ]
    }
   ],
   "source": [
    "def reduce_significance(hash_table, values):  \n",
    "    ## Create a data framreturn the results of the \n",
    "    ## the reduce process. The results are grouped by the first \n",
    "   \n",
    "    sig_level = 0.05\n",
    "    ncols = hash_table.shape[1]\n",
    "    nrows = hash_table.shape[0]\n",
    " \n",
    "    tt =ttest_ind(normal_vars[:,0], nr.normal(loc = 0.01, size=(1000,1)))\n",
    "    #1.Create an empty data frame with columns, i, j, t_statistic, and p_value.\n",
    "    #1a. I created an empty dataframe with i, j. so that t_statisticc and p_value\n",
    "    #    would be added later in a mass assignment\n",
    "    test_results = pd.DataFrame(columns=['i','j'])\n",
    " \n",
    "    count2 = 0\n",
    "    extract_i = []\n",
    "    extract_j = []\n",
    "    i_arr = []\n",
    "    j_arr = []\n",
    "    data = []\n",
    "    hash_arr  = []\n",
    "    hash_a = []\n",
    "    tt_arr = []\n",
    "    pv_arr = []\n",
    "    sig_arr = []\n",
    "    sig_count = 0\n",
    "\n",
    "    # 2. Used a for loop to iterate over all possible hashed keys of DataFrame hash_table\n",
    "    # Looping over all possible keys of the hash_table\n",
    "    for hash_num in range(hash_table.shape[0]): \n",
    "        if not np.isnan(hash_table.iloc[hash_num,0]):\n",
    "            # This is where you lookup in the hash table at super fast speeds\n",
    "            # 3. Extract the values of i and j from the input data frame\n",
    "            ival = hash_table.iloc[hash_num,0]\n",
    "            #\n",
    "            jval = hash_table.iloc[hash_num,1]\n",
    "            #\n",
    "            # 4. Using keys, compute the t-statistic and p-value using scipy.stats import ttest_ind.\n",
    "            tt = ttest_ind(values[:,ival] , values[:,jval]).statistic\n",
    "            #print(tt)\n",
    "            #print(str(len(tt)))\n",
    "            pv = ttest_ind(values[:,ival] , values[:,jval]).pvalue\n",
    "            \n",
    "            i_arr.append(values[:,ival])\n",
    "            j_arr.append(values[:,jval])\n",
    "            tt_arr.append(tt)\n",
    "            pv_arr.append(pv)\n",
    "            #sig_arr.append('SIG')\n",
    "            if (pv <= sig_level):\n",
    "                sig_arr.append('SIG')\n",
    "                sig_count += 1\n",
    "            else:\n",
    "                sig_arr.append('Not-Sig')\n",
    "            \n",
    "            #5. Append a row to the output data frame\n",
    "            data.append((ival,jval,hash_function(ival,jval)))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    print('len(hash_table): ' + str(len(hash_table)) )  \n",
    "   \n",
    "    #print('len(test_results): ' + str(len(test_results)) ) \n",
    "    print('len(tt_arr): '+ str(len(tt_arr)))\n",
    "    print('len(pv_arr): '+ str(len(pv_arr)))\n",
    "    print('len(sig_arr): '+ str(len(sig_arr)))\n",
    "    print('Sig-Count: ' + str(sig_count))\n",
    "    test_results = pd.DataFrame(data)\n",
    "    test_results.columns=['i','j','hash']\n",
    "    test_results.loc[:,'t_statistic'] = tt_arr\n",
    "    test_results.loc[:,'p_value'] = pv_arr\n",
    "    test_results.loc[:,'sig'] = sig_arr\n",
    "    #print('PRINT TEST_RESULTS')\n",
    "    #print(test_results.head())\n",
    "\n",
    "    #6.Return the data frame, sorted in ascending order, usin\n",
    "    return test_results.sort_values('p_value', axis=0, ascending=True).reset_index(drop=True)        \n",
    "        \n",
    "#7. Execute your function and save the returned data frame\n",
    "test_stats = reduce_significance(hash_table, normal_vars)\n",
    "test_stats.to_csv(\"test_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 8. In the cell below, create a filter for pair test cases which are significant and save these cases in a data frame. \n",
    "> 9. Print the number (len) of significant results.\n",
    "> 10. Print the rows with the significant test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(hash_table): 190\n",
      "len(tt_arr): 190\n",
      "len(pv_arr): 190\n",
      "len(sig_arr): 190\n",
      "Sig-Count: 22\n",
      "9. The length of the Significant Results are: 22\n",
      "10. The Significant Test Results are as Follows:\n",
      "     i   j   hash  t_statistic   p_value  sig\n",
      "0    0  17  17408    -3.992565  0.000068  SIG\n",
      "1    0   8   8192    -3.705426  0.000217  SIG\n",
      "2    0   4   4096    -3.311203  0.000946  SIG\n",
      "3    0   1   1024    -3.227865  0.001267  SIG\n",
      "4    0  16  16384    -3.024120  0.002525  SIG\n",
      "5    0  13  13312    -2.903111  0.003735  SIG\n",
      "6    0   5   5120    -2.872598  0.004114  SIG\n",
      "7   11  17  17595    -2.682146  0.007375  SIG\n",
      "8    0   7   7168    -2.681570  0.007388  SIG\n",
      "9    0   6   6144    -2.624430  0.008746  SIG\n",
      "10   0  10  10240    -2.462400  0.013885  SIG\n",
      "11   8  11  11352     2.422580  0.015499  SIG\n",
      "12   0   3   3072    -2.321463  0.020362  SIG\n",
      "13   0  14  14336    -2.294894  0.021842  SIG\n",
      "14   0  15  15360    -2.291186  0.022056  SIG\n",
      "15   0  19  19456    -2.279797  0.022725  SIG\n",
      "16   9  17  17561    -2.225359  0.026168  SIG\n",
      "17   0   2   2048    -2.212194  0.027066  SIG\n",
      "18   0  18  18432    -2.156647  0.031152  SIG\n",
      "19   0  12  12288    -2.031263  0.042360  SIG\n",
      "20   4  11  11308     2.017791  0.043747  SIG\n",
      "21   8   9   9288     1.980137  0.047825  SIG\n"
     ]
    }
   ],
   "source": [
    "significance_level = 0.05\n",
    "test_stats = reduce_significance(hash_table, normal_vars) \n",
    "## Put your code below. \n",
    "#print(test_stats)\n",
    "#8. In the cell below, create a filter for pair test cases\n",
    "#   which are significant and save these cases in a data frame.\n",
    "sig_filter_arr = test_stats.loc[test_stats['sig']=='SIG']\n",
    "\n",
    "df_sig = pd.DataFrame(sig_filter_arr)\n",
    "#print('The dataframe with Significant Results are as Follows:')\n",
    "#print(df_sig)\n",
    "# print(test_stats.head(10))\n",
    "\n",
    "print('9. The length of the Significant Results are: ' + str(test_stats.loc[test_stats['sig']=='SIG'].shape[0]))\n",
    "\n",
    "\n",
    "print('10. The Significant Test Results are as Follows:')\n",
    "print(test_stats.loc[test_stats['sig']=='SIG'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice the large number of apparently significant tests. Answer the following questions:  \n",
    "> 1. Is the number of false positive cases higher than expected? \n",
    "ANSWER 1. 22/190 = 0.11578.  Yes this is > our normal 5% acceptable cutoff for significance level\n",
    "> 2. Examine which of the iid Normal vectors contribute to the false positive results. Are there vectors which contribute multiple times? \n",
    "ANSWER 2. It looks like Column 0 is a high contributor to the false positive cases\n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. There seems to be an abundant number of possible False Positives. Column vector '0' seems to contribute to alot of these Significant cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonferroni correction  \n",
    "\n",
    "Several adjustments to the multiple comparisons problem have been proposed. In Dunn published a method know as the **Bonferroni correction** in 1961. The Bonferroni correction is a widely used method to reduce the false positive rate of hypothesis tests.  The adjustment is simple:\n",
    "$$\\alpha_b = \\frac{\\alpha}{m}\\\\\n",
    "with\\\\ \n",
    "m =\\ number\\ of\\ groups$$\n",
    "\n",
    "Can the Bonferroni correction help? Yes, by greatly increasing the confidence level required for a statistically significant result. The problem with the Bonferroni correction is the reduction in power as the  grows smaller. For big data problems with large numbers of groups, this issue can be especially serious. \n",
    "\n",
    "**Exercise 1-4:** You will now apply the Bonferroni correction to the iid Normal vectors. To do so, you will compute the Bonferroni threshold and the apply it to the p-values:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bon_nu_alpha: 0.0025\n",
      "len(hash_table): 190\n",
      "len(tt_arr): 190\n",
      "len(pv_arr): 190\n",
      "len(sig_arr): 190\n",
      "Sig-Count: 4\n",
      "9. The length of the Significant Results are: 4\n",
      "10. The Significant Test Results are as Follows:\n",
      "    i   j   hash  t_statistic   p_value  sig\n",
      "0   0   1   1024    -3.227865  0.001267  SIG\n",
      "3   0   4   4096    -3.311203  0.000946  SIG\n",
      "7   0   8   8192    -3.705426  0.000217  SIG\n",
      "16  0  17  17408    -3.992565  0.000068  SIG\n"
     ]
    }
   ],
   "source": [
    "## Exercise 1-4        \n",
    "## m = number of groups\n",
    "## alpha = confidence = 0.05\n",
    "\n",
    "def reduce_significance_bonferroni(hash_table, values,bon_alpha):  \n",
    "    ## Create a data framreturn the results of the \n",
    "    ## the reduce process. The results are grouped by the first \n",
    "   \n",
    "    sig_level = 0.05\n",
    "    ncols = hash_table.shape[1]\n",
    "    nrows = hash_table.shape[0]\n",
    " \n",
    "    tt =ttest_ind(normal_vars[:,0], nr.normal(loc = 0.01, size=(1000,1)))\n",
    "    #1.Create an empty data frame with columns, i, j, t_statistic, and p_value.\n",
    "    #1a. I created an empty dataframe with i, j. so that t_statisticc and p_value\n",
    "    #    would be added later in a mass assignment\n",
    "    test_results = pd.DataFrame(columns=['i','j'])\n",
    " \n",
    "    #Declarations\n",
    "    count2 = 0\n",
    "    extract_i = []\n",
    "    extract_j = []\n",
    "    i_arr = []\n",
    "    j_arr = []\n",
    "    data = []\n",
    "    hash_arr  = []\n",
    "    hash_a = []\n",
    "    tt_arr = []\n",
    "    pv_arr = []\n",
    "    sig_arr = []\n",
    "    sig_count = 0\n",
    "\n",
    "    # 2. Used a for loop to iterate over all possible hashed keys of DataFrame hash_table\n",
    "    # Looping over all possible keys of the hash_table\n",
    "    for hash_num in range(hash_table.shape[0]): \n",
    "        if not np.isnan(hash_table.iloc[hash_num,0]):\n",
    "            # This is where you lookup in the hash table at super fast speeds\n",
    "            # 3. Extract the values of i and j from the input data frame\n",
    "            ival = hash_table.iloc[hash_num,0]\n",
    "            #\n",
    "            jval = hash_table.iloc[hash_num,1]\n",
    "            #\n",
    "            # 4. Using keys, compute the t-statistic and p-value using scipy.stats import ttest_ind.\n",
    "            tt = ttest_ind(values[:,ival] , values[:,jval]).statistic\n",
    "            #print(tt)\n",
    "            #print(str(len(tt)))\n",
    "            pv = ttest_ind(values[:,ival] , values[:,jval]).pvalue\n",
    "            \n",
    "            i_arr.append(values[:,ival])\n",
    "            j_arr.append(values[:,jval])\n",
    "            tt_arr.append(tt)\n",
    "            pv_arr.append(pv)\n",
    "            #sig_arr.append('SIG')\n",
    "            if (pv <= bon_alpha):\n",
    "                sig_arr.append('SIG')\n",
    "                sig_count += 1\n",
    "            else:\n",
    "                sig_arr.append('Not-Sig')\n",
    "            \n",
    "            #5. Append a row to the output data frame\n",
    "            data.append((ival,jval,hash_function(ival,jval)))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    print('len(hash_table): ' + str(len(hash_table)) )  \n",
    "   \n",
    "    #print('len(test_results): ' + str(len(test_results)) ) \n",
    "    print('len(tt_arr): '+ str(len(tt_arr)))\n",
    "    print('len(pv_arr): '+ str(len(pv_arr)))\n",
    "    print('len(sig_arr): '+ str(len(sig_arr)))\n",
    "    print('Sig-Count: ' + str(sig_count))\n",
    "    test_results = pd.DataFrame(data)\n",
    "    test_results.columns=['i','j','hash']\n",
    "    test_results.loc[:,'t_statistic'] = tt_arr\n",
    "    test_results.loc[:,'p_value'] = pv_arr\n",
    "    test_results.loc[:,'sig'] = sig_arr\n",
    "    #print('PRINT TEST_RESULTS')\n",
    "    #print(test_results.head())\n",
    "\n",
    "    print('9. The length of the Significant Results are: ' + str(test_results.loc[test_results['sig']=='SIG'].shape[0]))\n",
    "\n",
    "\n",
    "    print('10. The Significant Test Results are as Follows:')\n",
    "    print(test_results.loc[test_results['sig']=='SIG'])\n",
    "\n",
    "    #6.Return the data frame, sorted in ascending order, usin\n",
    "    return test_results.sort_values('p_value', axis=0, ascending=True).reset_index(drop=True)        \n",
    "      \n",
    "       \n",
    "alpha = .05\n",
    "m = 20\n",
    "# Ex 1-4: You will now apply the Bonferroni correction to the iid Normal vectors. To do so, \n",
    "#         you will compute the Bonferroni threshold and the apply it to the p-values:\n",
    "bon_nu_alpha = alpha/m\n",
    "print('bon_nu_alpha: ' + str(bon_nu_alpha))\n",
    "bon_test_stats = reduce_significance_bonferroni(hash_table, normal_vars,bon_nu_alpha) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Even with the Bonferroni correction we have some false significance tests, if only just barely!    \n",
    "> **End of exercise.**\n",
    "\n",
    "But, can we detect small effect with Bonferroni correction, as this method significantly reduces power of tests? Execute the code in the cell below, which compares a standard Normal to a Normal with a small mean (effect size), to find out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=array([-2.49553488]), pvalue=array([0.01265684]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(567)\n",
    "\n",
    "\n",
    "ttest_ind(normal_vars[:,0], nr.normal(loc = 0.01, size=(1000,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the Bonferroni correction, this difference in means would not be found significant. This illustrates the downside of the correction, which may prevent detection of significant effects, while still finding false significance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Discovery Rate Control Methods \n",
    "\n",
    "We have seen the potential pitfalls of multiple hypothesis testing. Further, we have seen that a simple approach to **false discovery rate (FDR) control** is not effective. You will now apply more sophisticated FDR control methods to control the FDR. \n",
    "\n",
    "Inflammatory bowel disease is an auto immune disease that is characterized by chronic inflammation in the digestive tract. In 2020, there were around 2.5 million people with inflammatory bowel disease in the United States. It is estimated that the prevalence of IBD among U.S. population will rise to around 3.5 million by 2030.There are two forms of IBD: Ulcerative Colitis (UC) and Crohn’s disease (CD). \n",
    "\n",
    "The specific problem we will explore is to determine which genes lead to expression of a certain disease. In this example, there are gene expression data for 97 patients. Some of these patients have ulcerative colitis and others have Crohn's disease, which are believed to be genetically inherited.    \n",
    "\n",
    "One approach to this problem is to perform hypothesis tests on the expression of the genes between patients with the two conditions. Since there are over 10,000 genes there is considerable chance for false discovery. Therefore, careful application of FDR control is required.\n",
    "\n",
    "To continue with the example, execute the code in the cell below to load the data and print the dimensionality of the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dimensions of gene_data: (97, 10498)\n"
     ]
    }
   ],
   "source": [
    "gene_data = pd.read_csv('../data/ColonDiseaseGeneData-Cleaned.csv')\n",
    "print('The Dimensions of gene_data: ' + str(gene_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are data from 97 patients for 10,497 genes. A large number of hypothesis tests are required!     \n",
    "\n",
    "Execute the code in the cell below to view the first 5 columns of the data frame, which includes the expression of the first 4 genes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Disease State  FAM138F  LOC100133331  LOC100132062  LOC388312\n",
      "92  Crohn's Disease (CD)   7.3420        8.3204        8.5116     8.9684\n",
      "93  Crohn's Disease (CD)   6.6286        9.7240       10.2898    11.1171\n",
      "94  Crohn's Disease (CD)   6.7240        9.5739       10.2080    11.0556\n",
      "95  Crohn's Disease (CD)   7.5894        9.7265       10.3238    11.1514\n",
      "96  Crohn's Disease (CD)   7.4378        8.8964        9.3807    10.1370\n",
      "              Disease State  FAM138F  LOC100133331  LOC100132062  LOC388312\n",
      "0   Ulcerative Colitis (UC)   7.2980        8.5650        8.7778     9.2365\n",
      "1   Ulcerative Colitis (UC)   8.0751        8.3536        8.7785     9.4256\n",
      "2   Ulcerative Colitis (UC)   6.8458        8.8254        9.1960     9.8835\n",
      "3   Ulcerative Colitis (UC)   7.6507        8.1838        8.2845     8.8011\n",
      "4   Ulcerative Colitis (UC)   7.3524        8.4415        8.6630     9.1292\n",
      "92     Crohn's Disease (CD)   7.3420        8.3204        8.5116     8.9684\n",
      "93     Crohn's Disease (CD)   6.6286        9.7240       10.2898    11.1171\n",
      "94     Crohn's Disease (CD)   6.7240        9.5739       10.2080    11.0556\n",
      "95     Crohn's Disease (CD)   7.5894        9.7265       10.3238    11.1514\n",
      "96     Crohn's Disease (CD)   7.4378        8.8964        9.3807    10.1370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001ABABF9EFD0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gene_data.iloc[:,:5].tail(5 ))\n",
    "gd_head = pd.DataFrame(gene_data.iloc[:,:5].head())\n",
    "gd_tail = pd.DataFrame(gene_data.iloc[:,:5].tail(5))\n",
    "#gd_list = list(gene_data)\n",
    "\n",
    "abridgd_gd = pd.concat([gd_head, gd_tail])\n",
    "print(abridgd_gd)\n",
    "gene_data.groupby(['Disease State'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holm's method\n",
    "\n",
    "You will apply two FDR control methods to these data.These methods attempt to conod trol the FDR while not being overly conservative like the Bonferronic correction. The first of these Holm's method.    \n",
    "\n",
    "The Holm's method operates on the ordered set of p-values, $D = \\{ p_{(1)}, p_{(2)}, p_{(3)}, \\ldots, p_{(n)} \\}$. The threshold for the $ith$ p-value, $p(i) is:  \n",
    "\n",
    "$$p(i) \\le Threshold(Holm's) = \\frac{\\alpha}{N - i + 1}$$\n",
    "\n",
    "For example: for the 10th ordered p-value with 1,000 total tests (genes) and significance level of 0.05, the cutoff is:   \n",
    "\n",
    "$$p(10) \\le \\frac{0.05}{1000 - 10 + 1} = 0.00005045$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map process  \n",
    "\n",
    "> **Exercise 01-4:** To start the processing of these data you will first create and execute code for a map process. The map process groups the data by the patient's disease into data frame, ulcerative, crohns. The keys for each of these key-value pairs are the gene identifier. Notice that one key is all that is needed in this case. Now do the following to create and execute a function, `map_gene`:   \n",
    "> 1. Create a logical mask and group the values by `Disease State` into two data frames.\n",
    "> 2. Return the transpose of the two data frames, removing the `Disease State` values. The result of this operation should be data frames with gene expressions in the columns and the gene identifier as the row index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lonmc\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "def map_gene(gene_data):  \n",
    "    ## First, separate the columns by disease type  \n",
    "    #1. Create a logical mask and group the values by Disease State into two data frames\n",
    "    ## Put your code below.\n",
    "    df_crohns = pd.DataFrame(gene_data)\n",
    "    #df_ulcerative = pd.DataFrame(gene_data.iloc[:,:])\n",
    "    df_ulcerative = pd.DataFrame(gene_data)\n",
    "    c = df_crohns.loc[df_crohns['Disease State']==\"Crohn's Disease (CD)\"]\n",
    "    u = df_ulcerative.loc[df_crohns['Disease State']==\"Ulcerative Colitis (UC)\"]\n",
    "    \n",
    "    #2b. removing the Disease State values\n",
    "    c.drop('Disease State', inplace = True, axis = 1 )\n",
    "    u.drop('Disease State', inplace = True, axis = 1 )\n",
    "    \n",
    "    #2a. Return the transpose of the two data frames\n",
    "    c_T = c.transpose()\n",
    "    u_T = u.transpose()\n",
    "    #print(c_T)\n",
    "    #print(ulcerative)\n",
    "    return u_T, c_T\n",
    "#u = map_gene(gene_data)\n",
    "#2c.The result of this operation should be data frames with gene expressions in the columns and the gene identifier as the row index.' )\n",
    "ulcerative, crohns = map_gene(gene_data)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3. Execute the code in the cells below to display the heads of these data frames and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FAM138F</th>\n",
       "      <td>7.2980</td>\n",
       "      <td>8.0751</td>\n",
       "      <td>6.8458</td>\n",
       "      <td>7.6507</td>\n",
       "      <td>7.3524</td>\n",
       "      <td>7.2811</td>\n",
       "      <td>7.8913</td>\n",
       "      <td>7.0641</td>\n",
       "      <td>7.5266</td>\n",
       "      <td>7.0322</td>\n",
       "      <td>7.0657</td>\n",
       "      <td>7.5924</td>\n",
       "      <td>7.0600</td>\n",
       "      <td>7.1898</td>\n",
       "      <td>7.2143</td>\n",
       "      <td>7.0964</td>\n",
       "      <td>7.2198</td>\n",
       "      <td>7.3403</td>\n",
       "      <td>7.4461</td>\n",
       "      <td>7.3455</td>\n",
       "      <td>7.0880</td>\n",
       "      <td>7.2825</td>\n",
       "      <td>7.1724</td>\n",
       "      <td>6.8806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC100133331</th>\n",
       "      <td>8.5650</td>\n",
       "      <td>8.3536</td>\n",
       "      <td>8.8254</td>\n",
       "      <td>8.1838</td>\n",
       "      <td>8.4415</td>\n",
       "      <td>8.4023</td>\n",
       "      <td>8.8026</td>\n",
       "      <td>8.5498</td>\n",
       "      <td>8.8004</td>\n",
       "      <td>8.8119</td>\n",
       "      <td>8.6229</td>\n",
       "      <td>8.5463</td>\n",
       "      <td>8.7177</td>\n",
       "      <td>8.9140</td>\n",
       "      <td>8.5502</td>\n",
       "      <td>8.7591</td>\n",
       "      <td>9.2102</td>\n",
       "      <td>9.4456</td>\n",
       "      <td>8.5284</td>\n",
       "      <td>8.6927</td>\n",
       "      <td>8.2631</td>\n",
       "      <td>8.7345</td>\n",
       "      <td>8.3719</td>\n",
       "      <td>8.5305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC100132062</th>\n",
       "      <td>8.7778</td>\n",
       "      <td>8.7785</td>\n",
       "      <td>9.1960</td>\n",
       "      <td>8.2845</td>\n",
       "      <td>8.6630</td>\n",
       "      <td>8.6892</td>\n",
       "      <td>8.6892</td>\n",
       "      <td>8.7145</td>\n",
       "      <td>9.1334</td>\n",
       "      <td>9.1838</td>\n",
       "      <td>8.9592</td>\n",
       "      <td>9.1006</td>\n",
       "      <td>9.0183</td>\n",
       "      <td>9.4450</td>\n",
       "      <td>8.8953</td>\n",
       "      <td>9.2912</td>\n",
       "      <td>9.7642</td>\n",
       "      <td>10.0189</td>\n",
       "      <td>8.7357</td>\n",
       "      <td>9.0602</td>\n",
       "      <td>8.4369</td>\n",
       "      <td>9.1484</td>\n",
       "      <td>8.7555</td>\n",
       "      <td>8.8483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC388312</th>\n",
       "      <td>9.2365</td>\n",
       "      <td>9.4256</td>\n",
       "      <td>9.8835</td>\n",
       "      <td>8.8011</td>\n",
       "      <td>9.1292</td>\n",
       "      <td>9.3487</td>\n",
       "      <td>8.4706</td>\n",
       "      <td>9.0538</td>\n",
       "      <td>9.8241</td>\n",
       "      <td>9.8496</td>\n",
       "      <td>9.5281</td>\n",
       "      <td>9.7927</td>\n",
       "      <td>9.6008</td>\n",
       "      <td>10.1850</td>\n",
       "      <td>9.5342</td>\n",
       "      <td>9.9657</td>\n",
       "      <td>10.5014</td>\n",
       "      <td>10.7591</td>\n",
       "      <td>9.2506</td>\n",
       "      <td>9.7192</td>\n",
       "      <td>8.8794</td>\n",
       "      <td>9.7872</td>\n",
       "      <td>9.4038</td>\n",
       "      <td>9.3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC016143</th>\n",
       "      <td>7.3570</td>\n",
       "      <td>7.4431</td>\n",
       "      <td>7.5415</td>\n",
       "      <td>7.7199</td>\n",
       "      <td>7.4482</td>\n",
       "      <td>7.4577</td>\n",
       "      <td>8.6198</td>\n",
       "      <td>7.9258</td>\n",
       "      <td>7.4278</td>\n",
       "      <td>7.8487</td>\n",
       "      <td>7.3141</td>\n",
       "      <td>7.3871</td>\n",
       "      <td>7.5602</td>\n",
       "      <td>7.3844</td>\n",
       "      <td>7.2356</td>\n",
       "      <td>8.1990</td>\n",
       "      <td>7.4642</td>\n",
       "      <td>7.4081</td>\n",
       "      <td>7.7304</td>\n",
       "      <td>7.5309</td>\n",
       "      <td>7.9830</td>\n",
       "      <td>7.9588</td>\n",
       "      <td>7.5957</td>\n",
       "      <td>7.4893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1       2       3       4       5       6       7   \\\n",
       "FAM138F       7.2980  8.0751  6.8458  7.6507  7.3524  7.2811  7.8913  7.0641   \n",
       "LOC100133331  8.5650  8.3536  8.8254  8.1838  8.4415  8.4023  8.8026  8.5498   \n",
       "LOC100132062  8.7778  8.7785  9.1960  8.2845  8.6630  8.6892  8.6892  8.7145   \n",
       "LOC388312     9.2365  9.4256  9.8835  8.8011  9.1292  9.3487  8.4706  9.0538   \n",
       "BC016143      7.3570  7.4431  7.5415  7.7199  7.4482  7.4577  8.6198  7.9258   \n",
       "\n",
       "                  8       9       10      11      12       13      14      15  \\\n",
       "FAM138F       7.5266  7.0322  7.0657  7.5924  7.0600   7.1898  7.2143  7.0964   \n",
       "LOC100133331  8.8004  8.8119  8.6229  8.5463  8.7177   8.9140  8.5502  8.7591   \n",
       "LOC100132062  9.1334  9.1838  8.9592  9.1006  9.0183   9.4450  8.8953  9.2912   \n",
       "LOC388312     9.8241  9.8496  9.5281  9.7927  9.6008  10.1850  9.5342  9.9657   \n",
       "BC016143      7.4278  7.8487  7.3141  7.3871  7.5602   7.3844  7.2356  8.1990   \n",
       "\n",
       "                   16       17      18      19      20      21      22      23  \n",
       "FAM138F        7.2198   7.3403  7.4461  7.3455  7.0880  7.2825  7.1724  6.8806  \n",
       "LOC100133331   9.2102   9.4456  8.5284  8.6927  8.2631  8.7345  8.3719  8.5305  \n",
       "LOC100132062   9.7642  10.0189  8.7357  9.0602  8.4369  9.1484  8.7555  8.8483  \n",
       "LOC388312     10.5014  10.7591  9.2506  9.7192  8.8794  9.7872  9.4038  9.3340  \n",
       "BC016143       7.4642   7.4081  7.7304  7.5309  7.9830  7.9588  7.5957  7.4893  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulcerative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FAM138F</th>\n",
       "      <td>7.2068</td>\n",
       "      <td>7.8298</td>\n",
       "      <td>7.2091</td>\n",
       "      <td>7.0550</td>\n",
       "      <td>7.1302</td>\n",
       "      <td>7.5896</td>\n",
       "      <td>7.1414</td>\n",
       "      <td>7.5786</td>\n",
       "      <td>7.3579</td>\n",
       "      <td>7.2707</td>\n",
       "      <td>8.0351</td>\n",
       "      <td>7.5432</td>\n",
       "      <td>7.1810</td>\n",
       "      <td>7.5264</td>\n",
       "      <td>7.3716</td>\n",
       "      <td>7.4850</td>\n",
       "      <td>7.4165</td>\n",
       "      <td>6.9773</td>\n",
       "      <td>7.8786</td>\n",
       "      <td>7.5083</td>\n",
       "      <td>7.0880</td>\n",
       "      <td>6.8838</td>\n",
       "      <td>6.8119</td>\n",
       "      <td>7.2496</td>\n",
       "      <td>6.8267</td>\n",
       "      <td>7.0636</td>\n",
       "      <td>7.6835</td>\n",
       "      <td>7.2210</td>\n",
       "      <td>6.8487</td>\n",
       "      <td>7.5918</td>\n",
       "      <td>7.1678</td>\n",
       "      <td>7.3017</td>\n",
       "      <td>7.1610</td>\n",
       "      <td>7.2261</td>\n",
       "      <td>7.1593</td>\n",
       "      <td>7.1019</td>\n",
       "      <td>7.3116</td>\n",
       "      <td>7.8494</td>\n",
       "      <td>7.2701</td>\n",
       "      <td>7.5647</td>\n",
       "      <td>7.2515</td>\n",
       "      <td>7.1507</td>\n",
       "      <td>7.4678</td>\n",
       "      <td>7.5946</td>\n",
       "      <td>7.4190</td>\n",
       "      <td>7.1283</td>\n",
       "      <td>7.1075</td>\n",
       "      <td>7.5319</td>\n",
       "      <td>7.4337</td>\n",
       "      <td>6.8102</td>\n",
       "      <td>6.7455</td>\n",
       "      <td>7.4960</td>\n",
       "      <td>7.2845</td>\n",
       "      <td>7.0643</td>\n",
       "      <td>7.3322</td>\n",
       "      <td>7.2334</td>\n",
       "      <td>7.1355</td>\n",
       "      <td>7.3307</td>\n",
       "      <td>7.3263</td>\n",
       "      <td>7.5301</td>\n",
       "      <td>7.2411</td>\n",
       "      <td>7.7174</td>\n",
       "      <td>7.8088</td>\n",
       "      <td>6.8142</td>\n",
       "      <td>7.0029</td>\n",
       "      <td>7.1317</td>\n",
       "      <td>7.2842</td>\n",
       "      <td>7.0717</td>\n",
       "      <td>7.3420</td>\n",
       "      <td>6.6286</td>\n",
       "      <td>6.7240</td>\n",
       "      <td>7.5894</td>\n",
       "      <td>7.4378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC100133331</th>\n",
       "      <td>8.7216</td>\n",
       "      <td>8.9175</td>\n",
       "      <td>8.9301</td>\n",
       "      <td>8.5439</td>\n",
       "      <td>8.4071</td>\n",
       "      <td>8.6109</td>\n",
       "      <td>8.5179</td>\n",
       "      <td>8.5027</td>\n",
       "      <td>8.4111</td>\n",
       "      <td>8.4076</td>\n",
       "      <td>8.0996</td>\n",
       "      <td>8.3209</td>\n",
       "      <td>8.2516</td>\n",
       "      <td>8.7270</td>\n",
       "      <td>8.4931</td>\n",
       "      <td>8.3430</td>\n",
       "      <td>8.2109</td>\n",
       "      <td>8.3712</td>\n",
       "      <td>8.1959</td>\n",
       "      <td>8.5155</td>\n",
       "      <td>8.4385</td>\n",
       "      <td>8.4538</td>\n",
       "      <td>8.3748</td>\n",
       "      <td>8.9122</td>\n",
       "      <td>8.9778</td>\n",
       "      <td>9.4644</td>\n",
       "      <td>9.3493</td>\n",
       "      <td>8.7814</td>\n",
       "      <td>8.8734</td>\n",
       "      <td>8.2312</td>\n",
       "      <td>8.1288</td>\n",
       "      <td>9.2388</td>\n",
       "      <td>9.7806</td>\n",
       "      <td>9.3428</td>\n",
       "      <td>9.3831</td>\n",
       "      <td>8.3430</td>\n",
       "      <td>8.4065</td>\n",
       "      <td>8.3663</td>\n",
       "      <td>8.4757</td>\n",
       "      <td>8.8474</td>\n",
       "      <td>8.6235</td>\n",
       "      <td>8.8505</td>\n",
       "      <td>8.3267</td>\n",
       "      <td>8.6988</td>\n",
       "      <td>8.4272</td>\n",
       "      <td>8.6103</td>\n",
       "      <td>8.6806</td>\n",
       "      <td>8.8390</td>\n",
       "      <td>8.1981</td>\n",
       "      <td>8.4159</td>\n",
       "      <td>8.4007</td>\n",
       "      <td>9.1633</td>\n",
       "      <td>8.9434</td>\n",
       "      <td>8.2883</td>\n",
       "      <td>8.6903</td>\n",
       "      <td>8.4386</td>\n",
       "      <td>8.1473</td>\n",
       "      <td>8.6789</td>\n",
       "      <td>8.6000</td>\n",
       "      <td>8.5545</td>\n",
       "      <td>8.5200</td>\n",
       "      <td>8.6790</td>\n",
       "      <td>8.7493</td>\n",
       "      <td>9.1015</td>\n",
       "      <td>8.8982</td>\n",
       "      <td>8.5958</td>\n",
       "      <td>8.9521</td>\n",
       "      <td>8.7461</td>\n",
       "      <td>8.3204</td>\n",
       "      <td>9.7240</td>\n",
       "      <td>9.5739</td>\n",
       "      <td>9.7265</td>\n",
       "      <td>8.8964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC100132062</th>\n",
       "      <td>8.9883</td>\n",
       "      <td>9.1842</td>\n",
       "      <td>9.2968</td>\n",
       "      <td>8.8213</td>\n",
       "      <td>8.6142</td>\n",
       "      <td>8.8517</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>8.6525</td>\n",
       "      <td>8.6590</td>\n",
       "      <td>8.8388</td>\n",
       "      <td>8.1967</td>\n",
       "      <td>8.6573</td>\n",
       "      <td>8.4162</td>\n",
       "      <td>9.0187</td>\n",
       "      <td>8.7526</td>\n",
       "      <td>8.5856</td>\n",
       "      <td>8.3940</td>\n",
       "      <td>8.7869</td>\n",
       "      <td>8.5050</td>\n",
       "      <td>8.7980</td>\n",
       "      <td>8.8253</td>\n",
       "      <td>8.7470</td>\n",
       "      <td>8.5175</td>\n",
       "      <td>9.4422</td>\n",
       "      <td>9.3882</td>\n",
       "      <td>10.0785</td>\n",
       "      <td>9.8959</td>\n",
       "      <td>9.1714</td>\n",
       "      <td>9.2340</td>\n",
       "      <td>8.5544</td>\n",
       "      <td>8.3662</td>\n",
       "      <td>9.7731</td>\n",
       "      <td>10.4121</td>\n",
       "      <td>9.8967</td>\n",
       "      <td>9.8278</td>\n",
       "      <td>8.5420</td>\n",
       "      <td>8.4365</td>\n",
       "      <td>8.7258</td>\n",
       "      <td>8.8142</td>\n",
       "      <td>9.1067</td>\n",
       "      <td>8.8586</td>\n",
       "      <td>9.3616</td>\n",
       "      <td>8.4853</td>\n",
       "      <td>9.0260</td>\n",
       "      <td>8.7151</td>\n",
       "      <td>9.0461</td>\n",
       "      <td>9.0847</td>\n",
       "      <td>9.2998</td>\n",
       "      <td>8.4922</td>\n",
       "      <td>8.7216</td>\n",
       "      <td>8.6120</td>\n",
       "      <td>9.4830</td>\n",
       "      <td>9.1429</td>\n",
       "      <td>8.6007</td>\n",
       "      <td>9.0542</td>\n",
       "      <td>8.6074</td>\n",
       "      <td>8.4648</td>\n",
       "      <td>9.1033</td>\n",
       "      <td>8.7555</td>\n",
       "      <td>8.6041</td>\n",
       "      <td>8.9117</td>\n",
       "      <td>8.9892</td>\n",
       "      <td>8.9242</td>\n",
       "      <td>9.6005</td>\n",
       "      <td>9.1675</td>\n",
       "      <td>8.9374</td>\n",
       "      <td>9.2933</td>\n",
       "      <td>9.1679</td>\n",
       "      <td>8.5116</td>\n",
       "      <td>10.2898</td>\n",
       "      <td>10.2080</td>\n",
       "      <td>10.3238</td>\n",
       "      <td>9.3807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC388312</th>\n",
       "      <td>9.4779</td>\n",
       "      <td>9.6337</td>\n",
       "      <td>9.8979</td>\n",
       "      <td>9.4340</td>\n",
       "      <td>9.0457</td>\n",
       "      <td>9.3895</td>\n",
       "      <td>9.1508</td>\n",
       "      <td>8.9109</td>\n",
       "      <td>9.1606</td>\n",
       "      <td>9.4837</td>\n",
       "      <td>8.6139</td>\n",
       "      <td>9.2815</td>\n",
       "      <td>8.9155</td>\n",
       "      <td>9.5883</td>\n",
       "      <td>9.2896</td>\n",
       "      <td>9.1303</td>\n",
       "      <td>8.8056</td>\n",
       "      <td>9.4372</td>\n",
       "      <td>9.0982</td>\n",
       "      <td>9.3524</td>\n",
       "      <td>9.4505</td>\n",
       "      <td>9.2828</td>\n",
       "      <td>8.9693</td>\n",
       "      <td>10.1554</td>\n",
       "      <td>10.0778</td>\n",
       "      <td>10.8549</td>\n",
       "      <td>10.6338</td>\n",
       "      <td>9.8162</td>\n",
       "      <td>9.8769</td>\n",
       "      <td>9.1008</td>\n",
       "      <td>8.9679</td>\n",
       "      <td>10.5605</td>\n",
       "      <td>11.2396</td>\n",
       "      <td>10.6759</td>\n",
       "      <td>10.5998</td>\n",
       "      <td>8.9747</td>\n",
       "      <td>8.6799</td>\n",
       "      <td>9.3271</td>\n",
       "      <td>9.3429</td>\n",
       "      <td>9.6523</td>\n",
       "      <td>9.3837</td>\n",
       "      <td>10.0741</td>\n",
       "      <td>8.8199</td>\n",
       "      <td>9.5730</td>\n",
       "      <td>9.3093</td>\n",
       "      <td>9.6250</td>\n",
       "      <td>9.6714</td>\n",
       "      <td>9.9908</td>\n",
       "      <td>9.0470</td>\n",
       "      <td>9.2068</td>\n",
       "      <td>9.0240</td>\n",
       "      <td>10.0791</td>\n",
       "      <td>9.6071</td>\n",
       "      <td>9.1311</td>\n",
       "      <td>9.6266</td>\n",
       "      <td>9.0808</td>\n",
       "      <td>9.0846</td>\n",
       "      <td>9.6172</td>\n",
       "      <td>9.1330</td>\n",
       "      <td>8.8550</td>\n",
       "      <td>9.4735</td>\n",
       "      <td>9.5009</td>\n",
       "      <td>9.2937</td>\n",
       "      <td>10.3573</td>\n",
       "      <td>9.7203</td>\n",
       "      <td>9.6554</td>\n",
       "      <td>9.8822</td>\n",
       "      <td>9.7870</td>\n",
       "      <td>8.9684</td>\n",
       "      <td>11.1171</td>\n",
       "      <td>11.0556</td>\n",
       "      <td>11.1514</td>\n",
       "      <td>10.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC016143</th>\n",
       "      <td>8.0481</td>\n",
       "      <td>8.1224</td>\n",
       "      <td>7.8660</td>\n",
       "      <td>7.4640</td>\n",
       "      <td>7.7226</td>\n",
       "      <td>7.4770</td>\n",
       "      <td>7.7176</td>\n",
       "      <td>8.1704</td>\n",
       "      <td>7.8795</td>\n",
       "      <td>7.4256</td>\n",
       "      <td>7.6490</td>\n",
       "      <td>7.5086</td>\n",
       "      <td>7.3649</td>\n",
       "      <td>7.5547</td>\n",
       "      <td>7.4353</td>\n",
       "      <td>7.2359</td>\n",
       "      <td>7.6896</td>\n",
       "      <td>7.3325</td>\n",
       "      <td>7.5772</td>\n",
       "      <td>8.0188</td>\n",
       "      <td>7.7060</td>\n",
       "      <td>7.5093</td>\n",
       "      <td>7.4226</td>\n",
       "      <td>7.3826</td>\n",
       "      <td>7.4499</td>\n",
       "      <td>7.6519</td>\n",
       "      <td>7.3737</td>\n",
       "      <td>7.5800</td>\n",
       "      <td>7.5518</td>\n",
       "      <td>7.6202</td>\n",
       "      <td>7.3509</td>\n",
       "      <td>7.6288</td>\n",
       "      <td>7.8099</td>\n",
       "      <td>7.5718</td>\n",
       "      <td>7.6041</td>\n",
       "      <td>7.6090</td>\n",
       "      <td>8.1176</td>\n",
       "      <td>7.5379</td>\n",
       "      <td>7.8327</td>\n",
       "      <td>7.5541</td>\n",
       "      <td>7.8376</td>\n",
       "      <td>7.9190</td>\n",
       "      <td>7.8672</td>\n",
       "      <td>7.5682</td>\n",
       "      <td>7.4784</td>\n",
       "      <td>7.8521</td>\n",
       "      <td>7.6496</td>\n",
       "      <td>7.3517</td>\n",
       "      <td>7.4401</td>\n",
       "      <td>7.6754</td>\n",
       "      <td>7.8093</td>\n",
       "      <td>8.0799</td>\n",
       "      <td>7.8189</td>\n",
       "      <td>7.9144</td>\n",
       "      <td>7.9798</td>\n",
       "      <td>7.6367</td>\n",
       "      <td>7.5875</td>\n",
       "      <td>7.3403</td>\n",
       "      <td>7.6071</td>\n",
       "      <td>7.7039</td>\n",
       "      <td>7.9817</td>\n",
       "      <td>7.8251</td>\n",
       "      <td>8.0923</td>\n",
       "      <td>7.8580</td>\n",
       "      <td>8.2655</td>\n",
       "      <td>7.4652</td>\n",
       "      <td>7.6534</td>\n",
       "      <td>8.0463</td>\n",
       "      <td>7.7518</td>\n",
       "      <td>7.6910</td>\n",
       "      <td>7.8168</td>\n",
       "      <td>7.7033</td>\n",
       "      <td>7.4519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  24      25      26      27      28      29      30      31  \\\n",
       "FAM138F       7.2068  7.8298  7.2091  7.0550  7.1302  7.5896  7.1414  7.5786   \n",
       "LOC100133331  8.7216  8.9175  8.9301  8.5439  8.4071  8.6109  8.5179  8.5027   \n",
       "LOC100132062  8.9883  9.1842  9.2968  8.8213  8.6142  8.8517  8.7155  8.6525   \n",
       "LOC388312     9.4779  9.6337  9.8979  9.4340  9.0457  9.3895  9.1508  8.9109   \n",
       "BC016143      8.0481  8.1224  7.8660  7.4640  7.7226  7.4770  7.7176  8.1704   \n",
       "\n",
       "                  32      33      34      35      36      37      38      39  \\\n",
       "FAM138F       7.3579  7.2707  8.0351  7.5432  7.1810  7.5264  7.3716  7.4850   \n",
       "LOC100133331  8.4111  8.4076  8.0996  8.3209  8.2516  8.7270  8.4931  8.3430   \n",
       "LOC100132062  8.6590  8.8388  8.1967  8.6573  8.4162  9.0187  8.7526  8.5856   \n",
       "LOC388312     9.1606  9.4837  8.6139  9.2815  8.9155  9.5883  9.2896  9.1303   \n",
       "BC016143      7.8795  7.4256  7.6490  7.5086  7.3649  7.5547  7.4353  7.2359   \n",
       "\n",
       "                  40      41      42      43      44      45      46       47  \\\n",
       "FAM138F       7.4165  6.9773  7.8786  7.5083  7.0880  6.8838  6.8119   7.2496   \n",
       "LOC100133331  8.2109  8.3712  8.1959  8.5155  8.4385  8.4538  8.3748   8.9122   \n",
       "LOC100132062  8.3940  8.7869  8.5050  8.7980  8.8253  8.7470  8.5175   9.4422   \n",
       "LOC388312     8.8056  9.4372  9.0982  9.3524  9.4505  9.2828  8.9693  10.1554   \n",
       "BC016143      7.6896  7.3325  7.5772  8.0188  7.7060  7.5093  7.4226   7.3826   \n",
       "\n",
       "                   48       49       50      51      52      53      54  \\\n",
       "FAM138F        6.8267   7.0636   7.6835  7.2210  6.8487  7.5918  7.1678   \n",
       "LOC100133331   8.9778   9.4644   9.3493  8.7814  8.8734  8.2312  8.1288   \n",
       "LOC100132062   9.3882  10.0785   9.8959  9.1714  9.2340  8.5544  8.3662   \n",
       "LOC388312     10.0778  10.8549  10.6338  9.8162  9.8769  9.1008  8.9679   \n",
       "BC016143       7.4499   7.6519   7.3737  7.5800  7.5518  7.6202  7.3509   \n",
       "\n",
       "                   55       56       57       58      59      60      61  \\\n",
       "FAM138F        7.3017   7.1610   7.2261   7.1593  7.1019  7.3116  7.8494   \n",
       "LOC100133331   9.2388   9.7806   9.3428   9.3831  8.3430  8.4065  8.3663   \n",
       "LOC100132062   9.7731  10.4121   9.8967   9.8278  8.5420  8.4365  8.7258   \n",
       "LOC388312     10.5605  11.2396  10.6759  10.5998  8.9747  8.6799  9.3271   \n",
       "BC016143       7.6288   7.8099   7.5718   7.6041  7.6090  8.1176  7.5379   \n",
       "\n",
       "                  62      63      64       65      66      67      68      69  \\\n",
       "FAM138F       7.2701  7.5647  7.2515   7.1507  7.4678  7.5946  7.4190  7.1283   \n",
       "LOC100133331  8.4757  8.8474  8.6235   8.8505  8.3267  8.6988  8.4272  8.6103   \n",
       "LOC100132062  8.8142  9.1067  8.8586   9.3616  8.4853  9.0260  8.7151  9.0461   \n",
       "LOC388312     9.3429  9.6523  9.3837  10.0741  8.8199  9.5730  9.3093  9.6250   \n",
       "BC016143      7.8327  7.5541  7.8376   7.9190  7.8672  7.5682  7.4784  7.8521   \n",
       "\n",
       "                  70      71      72      73      74       75      76      77  \\\n",
       "FAM138F       7.1075  7.5319  7.4337  6.8102  6.7455   7.4960  7.2845  7.0643   \n",
       "LOC100133331  8.6806  8.8390  8.1981  8.4159  8.4007   9.1633  8.9434  8.2883   \n",
       "LOC100132062  9.0847  9.2998  8.4922  8.7216  8.6120   9.4830  9.1429  8.6007   \n",
       "LOC388312     9.6714  9.9908  9.0470  9.2068  9.0240  10.0791  9.6071  9.1311   \n",
       "BC016143      7.6496  7.3517  7.4401  7.6754  7.8093   8.0799  7.8189  7.9144   \n",
       "\n",
       "                  78      79      80      81      82      83      84      85  \\\n",
       "FAM138F       7.3322  7.2334  7.1355  7.3307  7.3263  7.5301  7.2411  7.7174   \n",
       "LOC100133331  8.6903  8.4386  8.1473  8.6789  8.6000  8.5545  8.5200  8.6790   \n",
       "LOC100132062  9.0542  8.6074  8.4648  9.1033  8.7555  8.6041  8.9117  8.9892   \n",
       "LOC388312     9.6266  9.0808  9.0846  9.6172  9.1330  8.8550  9.4735  9.5009   \n",
       "BC016143      7.9798  7.6367  7.5875  7.3403  7.6071  7.7039  7.9817  7.8251   \n",
       "\n",
       "                  86       87      88      89      90      91      92  \\\n",
       "FAM138F       7.8088   6.8142  7.0029  7.1317  7.2842  7.0717  7.3420   \n",
       "LOC100133331  8.7493   9.1015  8.8982  8.5958  8.9521  8.7461  8.3204   \n",
       "LOC100132062  8.9242   9.6005  9.1675  8.9374  9.2933  9.1679  8.5116   \n",
       "LOC388312     9.2937  10.3573  9.7203  9.6554  9.8822  9.7870  8.9684   \n",
       "BC016143      8.0923   7.8580  8.2655  7.4652  7.6534  8.0463  7.7518   \n",
       "\n",
       "                   93       94       95       96  \n",
       "FAM138F        6.6286   6.7240   7.5894   7.4378  \n",
       "LOC100133331   9.7240   9.5739   9.7265   8.8964  \n",
       "LOC100132062  10.2898  10.2080  10.3238   9.3807  \n",
       "LOC388312     11.1171  11.0556  11.1514  10.1370  \n",
       "BC016143       7.6910   7.8168   7.7033   7.4519  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crohns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce process \n",
    "\n",
    "> **Exercise 01-5:** With the key-value pairs organized by disease state, it is time to create and execute code of a reduce process. The reduce process will compute the pairwise t-statistics and p-values for each gene and return the sorted results. Specifically, your `gene_test` with arguments of the two mapped data frames will do the following:   \n",
    "> 1. Create an empty data frame with columns gene, t_statistics, and p-value.\n",
    "> 2. A for loop iterates over the keys of either of the data frames.  \n",
    "> 3. Compute the t-statistic and p-value for the gene (key).\n",
    "> 4. Append the results to the data frame.   \n",
    "> 5. Sort the results data frame, inplace, into ascending order.\n",
    "> 6. Return the resulting data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gene  t_statistic       p_value\n",
      "1119   CPQ    -6.868466  6.691708e-10\n",
      "3680  FOSB     6.356964  7.126189e-09\n",
      "3998  GBA3    -6.162788  1.719932e-08\n",
      "6958  LMNA     5.981750  3.873893e-08\n",
      "2016  DMKN     5.881375  6.051100e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10497, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gene_test(ulcerative, crohns):  \n",
    "\n",
    "    ## Put your code below. \n",
    "    tt_add = []\n",
    "    gene_arr = np.array(crohns.index)\n",
    "    \n",
    "    #2. A for loop iterates over the keys of either of the data frames.\n",
    "    for dis_key in crohns.index:\n",
    "        #3.Compute the t-statistic and p-value for the gene (key).\n",
    "        tt1 = ttest_ind(ulcerative.loc[dis_key,:] ,crohns.loc[dis_key,:]).statistic\n",
    "\n",
    "        pv1 = ttest_ind(ulcerative.loc[dis_key,:] ,crohns.loc[dis_key,:]).pvalue\n",
    "        #4. Append the results to the data frame\n",
    "        tt_add.append([dis_key,tt1,pv1])\n",
    "    #1. Create an empty data frame with columns gene, t_statistics, and p-value.\n",
    "    test_results = pd.DataFrame(tt_add,columns=['gene','t_statistic','p_value'])\n",
    "\n",
    "    test_results.set_index =('gene')\n",
    "    #5. Sort the results data frame, inplace, into ascending order\n",
    "    test_results.sort_values('p_value', axis=0, ascending=True,inplace = True) \n",
    "    #6. Return the resulting data frame\n",
    "    return test_results\n",
    "gene_statistics = gene_test(ulcerative, crohns) \n",
    "\n",
    "print(gene_statistics.head())\n",
    "gene_statistics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance of results \n",
    "\n",
    "With the gene data reduced to the t-test statistics, you will now determine the significance of these tests. It is important to understand that scientists believe that expression of a disease, like Corhn's, is only in a small number of genes.  \n",
    "\n",
    "> **Exercise 01-6:** As a first step in understanding the gene expression significance complete and execute the code in the cell below to find the number of 'significant' genes using the simple single hypothesis test cutoff criteria.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of significant genes are: 2548\n",
      "  Using the simple single hypothesis test cutoff criteria of alpha = 0.05.\n"
     ]
    }
   ],
   "source": [
    "significance_level =0.05\n",
    "## Put your code below. \n",
    "\n",
    "##gene_statistics = gene_test(ulcerative, crohns) \n",
    "significance_level = 0.05\n",
    "\n",
    "\n",
    "\n",
    "def find_the_significance(vars, sig_level):\n",
    "    #print(str(vars.shape))\n",
    "    #print('The sig level is: '+ str(sig_level))\n",
    "    sig_arr = []\n",
    "    vars.loc[:,'p_value']\n",
    "    #print(vars)\n",
    "    for v in range(len(vars)):\n",
    "        #if vars.loc[vars.loc['p_value'] <= sig_level]:\n",
    "        if vars.iloc[v][2]<= sig_level:\n",
    "            \n",
    "            sig_arr.append(True)\n",
    "        else:\n",
    "            sig_arr.append(False)\n",
    "    vars.loc[:,'significance']= sig_arr\n",
    "    return vars\n",
    "    #print(vars)\n",
    "df = find_the_significance(gene_statistics, significance_level)\n",
    "num_sig =len(df.loc[df.loc[:,'significance']== True,:])\n",
    "\n",
    "print('The number of significant genes are: ' + str(num_sig))\n",
    "print('  Using the simple single hypothesis test cutoff criteria of alpha = 0.05.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Does this large number of 'statistically significant' results appear credible, given that only a few genes are thought to have significant expression for this disease?   \n",
    "\n",
    "ANSWER: The total number of genes are: 10497 and 112/10497 gives 0.01067 or 1.06 %. This means\n",
    "there are within a reasonably acceptable range for Type I errors.  However it also means that\n",
    "we would have 112 significant cases to explore.  Would that mean although 0.01 acceptance of\n",
    "Type I erros, I feel 112 is a lot to ask for.\n",
    "> **End of exercise.**\n",
    "\n",
    "> **Exercise 01-7:** We have already seen that the Bonferroni correction is a rather conservative approach to testing the significance of large numbers of hypotheses. You will now use the Bonferroni correction to test the significance of the gene expression, by completing the code in the cell below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercis 01-7:\n",
      "The number of significant genes using the Bonferroni Correction are: 59\n",
      "  Using the corrected alpha test cutoff criteria 0.05/10497 = 0.00000476 as the new alpha.\n"
     ]
    }
   ],
   "source": [
    "## Put your code below. \n",
    "\n",
    "m = 10497\n",
    "alpha = 0.05\n",
    "bon_nu_alpha = alpha/m\n",
    "\n",
    "# Using a previously defined function from above\n",
    "df= find_the_significance(gene_statistics, bon_nu_alpha)\n",
    "\n",
    "num_sig =len(df.loc[df.loc[:,'significance']== True,:])\n",
    "\n",
    "print('Exercis 01-7:')\n",
    "print('The number of significant genes using the Bonferroni Correction are: ' + str(num_sig))\n",
    "print('  Using the corrected alpha test cutoff criteria 0.05/10497 = 0.00000476 as the new alpha.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The foregoing result seems reasonable, but is it too conservative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 01-08:** You will now apply the Holms method to determining significance of the gene expression test results. In the cell below complete the `holms_significance` function with arguments of the results data frame and the significance level. This function does the following:  \n",
    "> 1. Find the number of test results and compute the numerator used for the cutoff calculation. \n",
    "> 2. Compute the vector of thresholds using the Holms formula. Use the Python `range`function to get the values of the index i. But, keep in mind that range produces a zero-indexed iterator, and the algorithm needs a one-indexed list.  Use the [numpy.divide](https://numpy.org/doc/stable/reference/generated/numpy.divide.html) function to perform the vector divide. Save these threshold values in a data frame in a 'holms_threshold' column.   \n",
    "> 3. Using the threshold values compute a logical vector and save it in a column names 'significance' in the data frame.\n",
    "> 4. Return the data frame.\n",
    "> Finally, execute the function and save the results in a data frame. Then find the length of the subset where the 'significance' value is True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of test results used are: 10497\n",
      "The number of significant Holms test results are : 59\n",
      " \n",
      "The first (5) elements of the Holms_Results dataframe are listed below:\n",
      " \n",
      "   gene  t_statistic       p_value  significance  holms_threshold  row_num1  i\n",
      "0   CPQ    -6.868466  6.691708e-10          True         0.000005         1  0\n",
      "1  FOSB     6.356964  7.126189e-09          True         0.000005         2  1\n",
      "2  GBA3    -6.162788  1.719932e-08          True         0.000005         3  2\n",
      "3  LMNA     5.981750  3.873893e-08          True         0.000005         4  3\n",
      "4  DMKN     5.881375  6.051100e-08          True         0.000005         5  4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def holms_significance(test_results, significance):\n",
    "    ## First compute the thresholds for each of the ordered tests\n",
    "    #test_results.sort_values('p_value', axis=0, ascending = True).reset_index(drop=True)\n",
    "    test_results.shape\n",
    "    \n",
    "    ## Put your code below.\t\n",
    "    ## Declare vars\n",
    "    num_rows_arr = []\n",
    "    holms_sig =[]\n",
    "    isit_sig = []\n",
    "    order_i_num = []\n",
    "    alpha = significance\n",
    "    nrows = len(test_results)  # for index\n",
    "    num_rws = range(1,nrows+1,1)\n",
    "    \n",
    "    # create index array/ easy to manip df\n",
    "    for n in num_rws:\n",
    "        num_rows_arr.append(n)\n",
    " \n",
    "    # Let's not play with orig df\n",
    "    df_temp = test_results.copy()\n",
    "\n",
    " \n",
    "\n",
    "    # recall Holm's equation: p(i) <= Threshold(Holm) = alpha/(N- i + 1)\n",
    "    # 1b. and compute the numerator used for the cutoff calculation                                              alpha/denom\n",
    "    for irow in range(nrows):\n",
    "        numer = alpha                               # compute the numerator used for the cutoff calculation\n",
    "        denom = nrows +1- irow+1                    # the denominator used for cutoff calculation\n",
    "        # 2a. Compute the vector of thresholds using the Holms formula\n",
    "        # 2c. Use the numpy.divide function to perform the vector divide\n",
    "        theholms = np.divide(numer,denom)           # This is the combined Holms eqn\n",
    "        \n",
    "        thepval = df_temp.iloc[irow,2]              # This pulls the orig pval\n",
    "        holms_sig.append(theholms)                  # This creates the holms thresh\n",
    "        order_i_num.append(irow)\n",
    "        #3a.Using the threshold values compute a logical vector\n",
    "        if thepval <= theholms:                     # Ongoing determines significance\n",
    "            isit_sig.append(True)\n",
    "        else:\n",
    "            isit_sig.append(False)\n",
    "    #2d. Save these threshold values in a data frame in a 'holms_threshold' column.\n",
    "    df_temp.loc[:,'holms_threshold']= holms_sig     # creates columns in df_temp\n",
    "    #3b. save it in a column names 'significance' in the data frame.\n",
    "    df_temp.loc[:,'significance']= isit_sig         # ditto\n",
    "    #df_temp.sort_values('p_value', axis=0, ascending=True).reset_index(drop=True)\n",
    "    df_temp.loc[:,'row_num1']= num_rows_arr\n",
    "    df_temp.loc[:,'i'] = order_i_num\n",
    "    test_results= df_temp.copy()\n",
    "    #4. Return the data frame\n",
    "    return test_results.sort_values('p_value', axis=0, ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    ## Now we test the significance of the ordered p-values \n",
    "\n",
    "\n",
    "holms_results = holms_significance(gene_statistics, significance_level)\n",
    "\n",
    "#1a. Find the number of test results and compute the numerator used for the cutoff calculation\n",
    "print('The number of test results used are: '+ str(len(holms_results)))\n",
    "\n",
    "print('The number of significant Holms test results are : '+ str(len(holms_results.loc[holms_results.loc[:,'significance']== True,:])))\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print('The first (5) elements of the Holms_Results dataframe are listed below:')\n",
    "print(' ')\n",
    "print(holms_results.head())\n",
    "#1?. Find the number of test results. These are the number of Significant Holms results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Despite the general properties that the Holm's method is considered less conservative than the Bonferroni correction the results agree in this case. Does this agreement give you some confidence in the result and why?  \n",
    "ANSWER: Yes. Using two different means to predict the significant genes resulting in the same number of elements validates these two methods.  However we probably can't say for sure that each of the\n",
    "elements are the same. :) Maybe for another exercise\n",
    "> **End of exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the results of the Holm's method test. The plot has two key elements:  \n",
    "1. Plot the curve of the p-values vs. the order number, i. The line is color coded by significance or not.\n",
    "2. Plot the threshold line. This line is straight since the threshold is a linear function of i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-726dbee05f05>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['number'] = range(len(results))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(results)\n",
    "def plot_significance(results, threshold):\n",
    "    results['number'] = range(len(results))\n",
    "    #results['number'] = results.index\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.lineplot(x='number',y=threshold, data=results, ax=ax, color='black', linewidth=0.5)\n",
    "    sns.scatterplot(x='number',y='p_value', hue='significance', data=results, s=3, ax=ax)\n",
    "    ax.set_title('Significance of gene expression')\n",
    "    ax.set_xlabel('Gene number')\n",
    "    ax.set_ylabel('p-value')\n",
    "    \n",
    "plot_significance(holms_results.iloc[:500,:], 'holms_threshold')\n",
    "#plot_significance(holms_results.iloc[:500,:], 'p_value')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the following about this plot:  \n",
    "1. The p-value significance line crosses the threshold point at an apparent break point.   \n",
    "2. The significant p-values are all very small since there are so many tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benamini-Hochberg FDR Control \n",
    "\n",
    "The Benamini-Hochberg FDR control algorithm is another way to control false discoveries. Stat with an ordered set of $n$ p-values, $D = \\{ p_{(1)}, p_{(2)}, p_{(3)}, \\ldots, p_{(n)} \\}$ we define a false discovery rate, $q$:\n",
    "\n",
    "$$FDR(D) \\le q$$\n",
    "\n",
    "The cutoff threshold for the ith p-value is then:\n",
    "$$p_{(i)} \\le Threshold(D_q) = \\frac{q}{n} i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 01-9:** In this exercise you will apply the Benamini-Hochberg FDR control algorithm for testing the significance of the gene expressions. The `BH_significance` function is quite similar to the Holm's method function you have already created. Given the large number of genes you must use a low false discovery rate, $0.001$, or 1 out of 1,000. \n",
    "> Execute your function, saving the result. Then print the number of significant cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using the Benamini-Hochberg FDR Control:\n",
      " The number of total results were : 10497\n",
      " \n",
      "     Using the discovery rate,  0.001:\n",
      "     # Signifcant Results : 70\n",
      " \n",
      "     Using the discovery rate,  0.0001:\n",
      "     # Signifcant Results : 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def BH_significance(test_results, false_discovery_tollerance):\n",
    "    ## First compute the thresholds for each of the ordered tests\n",
    "    ## Put your code below. \n",
    "# Let's clean this up\n",
    "\n",
    "    ## Declare vars\n",
    "    num_rows_arr = []\n",
    "    bh_sig =[]\n",
    "    isit_sig = []\n",
    "    order_i_num = []\n",
    "    q = false_discovery_tollerance\n",
    "    nrows = len(test_results)  # for index\n",
    "    num_rws = range(1,nrows+1,1)\n",
    "    bh_sig = []\n",
    "    \n",
    "    # create index array/ easy to manip df\n",
    "    #for n in num_rws:ghost\n",
    "    #    num_rows_arr.append(n)\t\tghost\n",
    "\n",
    "    df_temp = test_results.copy()\n",
    "    # order original p_values from smallest to Largest\n",
    "    df_temp.sort_values('p_value', axis=0, ascending = True).reset_index(drop=True)\n",
    "\n",
    "    #df_temp.loc[:,'row_num1']= num_rows_arr  ghost\t\n",
    "\n",
    "    # recall B-H equation: p(i) <= \tThreshold(D-subq) = (q * i) / n\n",
    "    #                               where FDR(D) <= q\t\n",
    "    #                               D = { p(1), p(2),..p(n)}\n",
    "    #                               q : false Discover Rate\n",
    "    \n",
    "    # EXERCISE REQUIREMENT: apply the Benamini-Hochberg FDR control algorithm \n",
    "    \n",
    "    for irow in range(nrows):       # this actually should correspond to index of ord pval\n",
    "        denom = nrows\n",
    "        numer = q * irow\n",
    "        the_bh = np.divide(numer,denom)         # This is the eqn\n",
    "        thepval = df_temp.iloc[irow,2]          # This pulls the orig pval: checked col 'p_value' \n",
    "                                                #    corresponds to this col # 2\n",
    "        bh_sig.append(the_bh)                   # This creates the bh thresh\n",
    "        order_i_num.append(irow)\n",
    "        if thepval <= the_bh:                   # Ongoing determines significance\n",
    "            isit_sig.append(True)\n",
    "        else:\n",
    "            isit_sig.append(False)\n",
    "    #df_temp.drop('row_num1', inplace=True, axis=1)\n",
    "    #df_temp.drop('row_num1', inplace=True, axis=1)\n",
    "    df_temp.loc[:,'bh_threshold']= bh_sig       # creates columns in df_temp\n",
    "    df_temp.loc[:,'significance']= isit_sig     # ditto\n",
    "\n",
    "    # Now to traverse the DataFrame from the bottom up leaving all in place\n",
    "    for find_max_sig_ind in range(nrows-1,-1,-1):\n",
    "        if df_temp['significance'][find_max_sig_ind]== True:\n",
    "            max_index = find_max_sig_ind        # Flags where the max Significant pvalue is\n",
    "            break                               # that's all the info we want here\n",
    " \n",
    "    for bottomup_ind in range(max_index,nrows-1, -1):\n",
    "        #df_temp.loc[:,'significance'] == True\n",
    "        df_temp['significance'][bottomup]= True\n",
    " \n",
    "    #df_temp.sort_values('p_value', axis=0, ascending=True).reset_index(drop=True)\n",
    "    #df_temp.loc[:,'row_num1']= num_rows_arr\n",
    "    #df_temp.loc[:,'i'] = order_i_num\n",
    "     \n",
    "    return df_temp\n",
    "#Exercise 01-9:\n",
    "BH_results = BH_significance(gene_statistics, 0.001) \n",
    "print(' Using the Benamini-Hochberg FDR Control:')\n",
    "print(' The number of total results were : ' + str(len(BH_results)))\n",
    "print(' ')\n",
    "print('     Using the discovery rate,  0.001:')\n",
    "print('     # Signifcant Results : ' + str(len(BH_results.loc[BH_results.loc[:,'significance'],:])))\n",
    "print(' ')\n",
    "BH_0001 = BH_significance(gene_statistics, 0.0001)\n",
    "print('     Using the discovery rate,  0.0001:')\n",
    "print('     # Signifcant Results : ' + str(len(BH_0001.loc[BH_0001.loc[:,'significance'],:])))\n",
    "print('')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The result is similar to the first two FDR control methods. Given the false discovery parameter of 0.0001 do you think this is a reasonable result? \n",
    "\n",
    "Yes. There are 70 discoveries from the BH test using a False Discover Rate of 0.001. The False Discovery Rate of 0.0001  shows a greatly reduced number: 2. But we might check for Type II Results\n",
    "where there are False negatives. We want the probability of Type I false positives to be less than\n",
    "0.05 or 5%. This test results shows a predicted number of 70/10497 = 0.000696538. Which I would think is acceptable at .069%. and with the Discovery Rate of 0.0001 we get 2/10497 = 0.000190531 or .019%.\n",
    "The question we must ask ourselves is, can we live with the possibility of missed discoveries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, execute the code in the cell below and examine the resulting plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-726dbee05f05>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['number'] = range(len(results))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BH_results.sort_values('p_value', axis=0, ascending=True).reset_index(drop=True)\n",
    "plot_significance(BH_results.iloc[:500,:], 'bh_threshold')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 01-10**: Bonus question. Compare the plot above to the foregoing plot for Holm's method. Are the breaks in slope of the p-value curve at the crossing point with the threshold values reasonable in both cases? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright 2021, Stephen F. Elston. All rights reserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
